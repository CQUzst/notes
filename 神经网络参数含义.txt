1. cfg文件参数含义
batch:每一次迭代送到网络的图片数量，也叫批数量。增大这个可以让网络在较少的迭代次数内完成一个epoch。
    在固定最大迭代次数的前提下，增加batch会延长训练时间，但会更好的寻找到梯度下降的方向。
    如果你显存够大，可以适当增大这个值来提高内存利用率。这个值是需要大家不断尝试选取的，过小的话会让训练不够收敛，过大会陷入局部最优。
subdivision：这个参数很有意思的，它会让你的每一个batch不是一下子都丢到网络里。而是分成subdivision对应数字的份数，
    一份一份的跑完后，在一起打包算作完成一次iteration。这样会降低对显存的占用情况。
    如果设置这个参数为1的话就是一次性把所有batch的图片都丢到网络里，如果为2的话就是一次丢一半。
angle：图片旋转角度，这个用来增强训练效果的。从本质上来说，就是通过旋转图片来变相的增加训练样本集。
saturation，exposure，hue：饱和度，曝光度，色调，这些都是为了增强训练效果用的。
learning_rate：学习率，训练发散的话可以降低学习率。学习遇到瓶颈，loss不变的话也减低学习率。
max_batches： 最大迭代次数。
policy：学习策略，一般都是step这种步进式。
step，scales：这两个是组合一起的，
    举个例子：learn_rate: 0.001, step:100,25000,35000   scales: 10, .1, .1
    这组数据的意思就是在0-100次iteration期间learning rate为原始0.001，
    在100-25000次iteration期间learning rate为原始的10倍0.01，
    在25000-35000次iteration期间learning rate为当前值的0.1倍，就是0.001， 
    在35000到最大iteration期间使用learning rate为当前值的0.1倍，就是0.0001。
    随着iteration增加，降低学习率可以是模型更有效的学习，也就是更好的降低train loss。
    最后一层卷积层中filters数值是 5×（类别数 + 5）。region里需要把classes改成你的类别数。
    最后一行的random，是一个开关。如果设置为1的话，就是在训练的时候每一batch图片会随便改成320-640（32整倍数）大小的图片。
    目的和上面的色度，曝光度等一样。如果设置为0的话，所有图片就只修改成默认的大小 416*416。
2. 训练log中各参数的意义
Region Avg IOU：平均的IOU，代表预测的bounding box和ground truth的交集与并集之比，期望该值趋近于1。
Class：是标注物体的概率，期望该值趋近于1.
Obj：期望该值趋近于1.
No Obj：期望该值越来越小但不为零.
Avg Recall：期望该值趋近1
avg：平均损失，期望该值趋近于0
rate：当前学习率
